{
 "metadata": {
  "name": "Logbook"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# ISFINDER NOTEBOOK\n",
      "\n",
      "# 2014 05 20\n",
      "\n",
      "### Input Data\n",
      "\n",
      "* Paired fastq.gz file (an artificial dataset can be generated using [ISIS](https://github.com/a-slide/Isis)\n",
      "* Reference genome of virus and host DNA in fasta format\n",
      "* Annotation files of host reference genome to locate features such as genes, CpG, active chromatine... (Bed format?)\n",
      "* Configuration file containing all algorithm parameters\n",
      "* output name use as a prefix for output data\n",
      "\n",
      "### Required Output (for biologists...)\n",
      "\n",
      "* After a de *novo* reconstruction of junctions from chimeric pairs and reads a report containing the characteristics of each junction and the number of reads in support of its exxistence will be generated\n",
      "\n",
      "* To visualize junctions a fasta reference of reconstructed will be generated and BAM/BAI/bedGraph file containing supported reads will also be generated \n",
      "\n",
      "* In addition, BAM, BAM index and BedGraph for the following categories of sequences\n",
      "    * Unmapped sequences (BAM only)\n",
      "    * Both mate of a pair in virus genome\n",
      "    * Both mate of a pair in host genome\n",
      "    * Pairs ovelapping true junctions\n",
      "    * Pairs corresponding to NGS prep artifacts (not a true junction)\n",
      "\n",
      "* A circos plot of insertion distribution in host genome will be created with Circos\n",
      "\n",
      "* Using host genome annotation feature, the enrichment of junction nears specific feature will be summurize in a report (CpG, Gene, heterochromatin...)\n",
      "\n",
      "### Specificity of the analysis\n",
      "\n",
      "1. Extract virus/host genome junctions in pair end sequencing data : Junction could be inside a read (chimeric read) or between the 2 mate of a pair (chimeric pairs)\n",
      "2. Bad quality sequences may result in unmapped reads or false positive\n",
      "3. A large number of sequence may result in extensive calculation time   \n",
      "4. Homology between virus and fragment of host genome may result in false positive junctions.\n",
      "5. Filter out false junctions created during NGS library preparation\n",
      "\n",
      "\n",
      "### Suggested solutions\n",
      "\n",
      "1. Map the dataset against a fused reference containg both virus and host genome with a BWT based aligner. The aligner need to be able to detect and report reads party aligned on 2 reference2. The SAM result can be subsequently pardes to extract chimeric reads. \n",
      "2. To avoid a negative impact of bad quality and unrelated sequence, a primary facultative step including quality and adapter trimming will be implemented\n",
      "3. If possible, heavy calculating steps will be parallelize with either CPU or GPU distribution. Bowtie2, BWA, BWA_PSSM and BALSA will be benchmarked side by side to compare precision and execution time with a artificial dataset generated with [ISIS](https://github.com/a-slide/Isis).\n",
      "4. A facultative step of homology masking in host genome will be implemented using results of a virus genome blast against the host genome. We will compared the precision with or without this step.\n",
      "5. From all chimeric reads and pair a *de novo* assembly to reconstruct junctions will performed. True junctions will be defined by selecting junctions supported by either a least a fixed count (ex = 5) or above a dynamic background established thanks to a biological control (non infected animal)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2014 05 21\n",
      "\n",
      "###\u00a0Initial design proposed for IsFinder\n",
      "\n",
      "![Design](files/img/Initial_design.svg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exploration of Blast integration in biopython = Drafting function for CoordHits\n",
      "\n",
      "NCBIWWW module = BLAST over the Internet"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast.NCBIWWW import qblast\n",
      "qblast('blastn', 'nr', 'ATATCCGTAGTATTTATATGCGCGTAGCTCGCTGCTTATTATCGCTGATCTC')\n",
      "# Dos not work in the lab due to the proxy server..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In all cases this online requesting tool is not suitable for IsFind pipeline. Blast need to be run locally with a local dadabase consisting only of host genomic DNA. For this we can use the NCBI BLASTX wrapper from the Bio.Blast.Application"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast.Applications import NcbiblastxCommandline as blast\n",
      "help(blast)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A blast database had to be prepared before using blast\n",
      "\n",
      "Test of makeblast in bash shell.\n",
      "\n",
      "call or check call had to be used to launch command line in the shell\n",
      "check call is better since it raise a CalledProcessError in case of failure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# command line with an error\n",
      "from subprocess import check_call\n",
      "check_call((\"makeblastdb -in multi.fa -dbtype nucl -input_type fast\"), shell=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# command line without error\n",
      "check_call((\"makeblastdb -in multi.fa -dbtype nucl -input_type fasta\"), shell=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Command line execution function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import check_call, CalledProcessError\n",
      "\n",
      "def command_bool(command):\n",
      "    \"\"\" Generic function to execute command lines return true or false\n",
      "    \"\"\"\n",
      "    try:\n",
      "        print (command)\n",
      "        check_call((command), shell=True)\n",
      "        print (\"Success\")\n",
      "    except (OSError, CalledProcessError) as E:\n",
      "        print (E)\n",
      "        exit (0)\n",
      "\n",
      "#Definition of the reference and construction of the command text line\n",
      "reference = \"multi.fa\"\n",
      "command = \"makeblastdb -in {0} -dbtype nucl -input_type fasta\".format(reference)\n",
      "\n",
      "# Call of command_line\n",
      "command_bool(command)\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Blastn using biopython parser = not much informative and can be easily done without"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast.Applications import NcbiblastnCommandline as blastn\n",
      "\n",
      "command = blastn(query=\"frag.fa\", db=\"multi.fa\", evalue=0.001, outfmt=1, out=\"test.xml\")\n",
      "print (command)\n",
      "\n",
      "stdout, stderr = command()\n",
      "print (stdout)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using my command_bool functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query = \"frag.fa\"\n",
      "db = \"multi.fa\"\n",
      "command = \"blastn -outfmt '6 sseqid sstart send' -query {0} -db {1} -evalue 0.001\".format(query, db)\n",
      "\n",
      "# Call of command_line\n",
      "print (command_bool(command))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Call or check_call are not able to return the command line return value. Instead Popen should be used for this"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import Popen, PIPE\n",
      "\n",
      "def command_return(command):\n",
      "    \"\"\" Generic function to execute command lines return true or false\n",
      "    \"\"\"\n",
      "    try:\n",
      "        print (command)\n",
      "        return Popen(command, shell=True, stdout=PIPE).stdout.read()\n",
      "    except (OSError, ValueError) as E:\n",
      "        print (E)\n",
      "        exit (0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query = \"frag.fa\"\n",
      "db = \"multi.fa\"\n",
      "command = \"blastn -outfmt '6 sseqid sstart send' -query {0} -db {1} -evalue 0.001\".format(query, db)\n",
      "\n",
      "# Call of command_line\n",
      "command_return(command)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It work and return a list of string with each string composed of the subject ref name followed by the start and end of the blast hit. Now Let's build fonctions to parse this results and store it in a dictionnary.\n",
      "\n",
      "# 2014 05 22\n",
      "\n",
      "### Split lines from a raw blast CSV output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_blast_lines (command):\n",
      "    return [i for i in command_return(command).splitlines()]\n",
      "        \n",
      "split_blast(\"blastn -outfmt '6 sseqid sstart send' -query frag.fa -db multi.fa -evalue 0.001\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### List Version of blast hits results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_blast (command):\n",
      "    return [i.split(\"\\t\") for i in split_blast_lines (command)]\n",
      "\n",
      "list_blast(\"blastn -outfmt '6 sseqid sstart send' -query frag.fa -db multi.fa -evalue 0.001\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Dict Version of blast hits results (with additional str to int conversion of start and end)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dict_blast (command):\n",
      "    d = {}\n",
      "    for ref, start, end in list_blast(command):\n",
      "        if ref in d:\n",
      "            d[ref].append([int(start), int(end)])\n",
      "        else:\n",
      "            d[ref] = [[int(start), int(end)]]\n",
      "    return d\n",
      "\n",
      "dict_blast(\"blastn -outfmt '6 sseqid sstart send' -query frag.fa -db multi.fa -evalue 0.001\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Summary of functions for CoordHits\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import Popen, PIPE\n",
      "\n",
      "def command_return(command):\n",
      "    try:\n",
      "        return (Popen(command, shell=True, stdout=PIPE).stdout.read())\n",
      "    except (OSError, ValueError) as E:\n",
      "        print (E)\n",
      "        exit (0)    \n",
      "\n",
      "def split_blast_lines (command):\n",
      "    return [i for i in command_return(command).splitlines()]\n",
      "\n",
      "def list_blast (command):\n",
      "    list_blast = [i.split(\"\\t\") for i in split_blast_lines (command)]\n",
      "    print (\"{0} hit(s) found\".format(len(list_blast)))\n",
      "    return list_blast\n",
      "\n",
      "def dict_blast (command):\n",
      "    d = {}\n",
      "    for ref, pos1, pos2 in list_blast(command):\n",
      "        \n",
      "        # Cast positions in integers\n",
      "        pos1 = int(pos1)\n",
      "        pos2 = int(pos2)\n",
      "        \n",
      "        # Return end and start in the appropriate order\n",
      "        start = pos1 if pos1 <= pos2 else pos2\n",
      "        end = pos2 if pos1 <= pos2 else pos1\n",
      "        \n",
      "        # Fill the dictionary iteratively\n",
      "        if ref in d:\n",
      "            d[ref].append([start, end])\n",
      "        else:\n",
      "            d[ref] = [[start, end]]\n",
      "    return d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Definition of the reference and construction of the command text line\n",
      "query = \"../data/AAV_RSV_GFP.fa\"\n",
      "subject = \"../data/mm10.fa\"\n",
      "cmd = \"makeblastdb -in {0} -dbtype nucl -input_type fasta\".format(subject)\n",
      "\n",
      "print (\"Creating subject database\") \n",
      "print(command_return(cmd))\n",
      "\n",
      "print (\"Blast {0} against {1} database\".format(query, subject))\n",
      "cmd = \"blastn -outfmt '6 sseqid sstart send' -query {0} -db {1} -evalue 0.1\".format(query, subject)\n",
      "dict_blast(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating subject database\n",
        "\n",
        "\n",
        "Building a new DB, current time: 05/22/2014 14:45:17\n",
        "New DB name:   ../data/mm10.fa\n",
        "New DB title:  ../data/mm10.fa\n",
        "Sequence type: Nucleotide\n",
        "Keep Linkouts: T\n",
        "Keep MBits: T\n",
        "Maximum file size: 1000000000B\n",
        "Adding sequences from FASTA; added 66 sequences in 33.2092 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Blast ../data/AAV_RSV_GFP.fa against ../data/mm10.fa database\n",
        "6 hit(s) found"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{'chr12': [[115158736, 115158705],\n",
        "  [115208428, 115208397],\n",
        "  [115372318, 115372287],\n",
        "  [115461332, 115461301],\n",
        "  [115758317, 115758286],\n",
        "  [115802981, 115802950]]}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It works with the whole mouse genome versus an AAV genome. It is really fast even taking into account database building (> 1 min). However Blast option needs to be optimize since only few hits are found only in chr12. The blast User Manuel may help to determine better parameters [USER MANUAL](http://www.ncbi.nlm.nih.gov.gate2.inist.fr/books/NBK1763/?report=reader)\n",
      "\n",
      "blastn algorithm seems more adapted than the default option megablast to find partial matches, but it is also a little slower.\n",
      "Parameters were change to increase the number of hits:\n",
      "\n",
      "* -evalue was remove to reach its default value = 10\n",
      "* -dust was deactivated to avoid query filtering\n",
      "* -num_threads was added to use parralel CPU processing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from multiprocessing import cpu_count\n",
      "\n",
      "def blastn_hits (query, subject, evalue=10):\n",
      "    \n",
      "    cmd = \"makeblastdb -in {0} -dbtype nucl -input_type fasta\".format(subject)\n",
      "    print (\"Creating subject database\") \n",
      "    print(command_return(cmd))\n",
      "    \n",
      "    cmd = \"blastn -task blastn -outfmt '6 sseqid sstart send' -dust no -num_threads {0} -evalue {1} -query {2} -db {3}\".format(\n",
      "        cpu_count(),\n",
      "        evalue,\n",
      "        query,\n",
      "        subject)\n",
      "    \n",
      "    print (\"Blast query against subject database\")\n",
      "    return (dict_blast(cmd))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blastn_hits (\"../data/AAV_RSV_GFP.fa\", \"../data/mm10.fa\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating subject database\n",
        "\n",
        "\n",
        "Building a new DB, current time: 05/22/2014 18:21:06\n",
        "New DB name:   ../data/mm10.fa\n",
        "New DB title:  ../data/mm10.fa\n",
        "Sequence type: Nucleotide\n",
        "Keep Linkouts: T\n",
        "Keep MBits: T\n",
        "Maximum file size: 1000000000B\n",
        "Adding sequences from FASTA; added 66 sequences in 35.1908 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Blast query against subject database\n",
        "82 hit(s) found"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "{'chr1': [[135431782, 135431802]],\n",
        " 'chr10': [[21803986, 21804030], [96251960, 96251991]],\n",
        " 'chr11': [[105405046, 105405075]],\n",
        " 'chr12': [[115158705, 115158736],\n",
        "  [115208397, 115208428],\n",
        "  [115372287, 115372318],\n",
        "  [115461301, 115461332],\n",
        "  [115758286, 115758317],\n",
        "  [115802950, 115802981],\n",
        "  [115120050, 115120081],\n",
        "  [115335384, 115335415],\n",
        "  [115507847, 115507878],\n",
        "  [114583871, 114583902],\n",
        "  [114991410, 114991441],\n",
        "  [115888398, 115888429],\n",
        "  [114708950, 114708983],\n",
        "  [114736547, 114736580],\n",
        "  [114740710, 114740743],\n",
        "  [114746575, 114746608],\n",
        "  [114788674, 114788707],\n",
        "  [116000330, 116000363],\n",
        "  [115848183, 115848217],\n",
        "  [114666174, 114666207],\n",
        "  [114773230, 114773263],\n",
        "  [114851492, 114851525],\n",
        "  [114880190, 114880223],\n",
        "  [115055527, 115055558],\n",
        "  [115495927, 115495958],\n",
        "  [115623463, 115623494],\n",
        "  [115790896, 115790927],\n",
        "  [115920581, 115920612],\n",
        "  [114469404, 114469435],\n",
        "  [114598195, 114598229],\n",
        "  [114677050, 114677081],\n",
        "  [114963683, 114963714],\n",
        "  [115145789, 115145820],\n",
        "  [115193977, 115194008],\n",
        "  [115359442, 115359473],\n",
        "  [115593412, 115593443],\n",
        "  [50962553, 50962576],\n",
        "  [73507255, 73507283],\n",
        "  [73507255, 73507283],\n",
        "  [114555911, 114555941],\n",
        "  [115131678, 115131708],\n",
        "  [115344840, 115344870],\n",
        "  [115692191, 115692219]],\n",
        " 'chr13': [[105389688, 105389721]],\n",
        " 'chr14': [[9712542, 9712567]],\n",
        " 'chr15': [[74947775, 74947819], [8584656, 8584686], [54513789, 54513829]],\n",
        " 'chr17': [[76074925, 76074954], [59435556, 59435583], [85732858, 85732878]],\n",
        " 'chr18': [[33170801, 33170827], [38919602, 38919635], [38919602, 38919635]],\n",
        " 'chr2': [[76167874, 76167906]],\n",
        " 'chr3': [[53139723, 53139747],\n",
        "  [108069438, 108069459],\n",
        "  [108806632, 108806657]],\n",
        " 'chr4': [[145768347, 145768379],\n",
        "  [146257233, 146257265],\n",
        "  [146597820, 146597852]],\n",
        " 'chr5': [[106926004, 106926034], [106926004, 106926034]],\n",
        " 'chr7': [[94737490, 94737516],\n",
        "  [19426491, 19426538],\n",
        "  [29229444, 29229476],\n",
        "  [29229444, 29229476]],\n",
        " 'chr8': [[82071122, 82071150], [118282667, 118282697]],\n",
        " 'chr9': [[25988281, 25988307],\n",
        "  [10114568, 10114593],\n",
        "  [21196729, 21196752],\n",
        "  [21196729, 21196752],\n",
        "  [21196729, 21196752],\n",
        "  [21196729, 21196752],\n",
        "  [45047714, 45047742],\n",
        "  [59962726, 59962756]],\n",
        " 'chrX': [[120341475, 120341508]]}"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These parameters sound suitable for a future implementation of HitCoord class"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using hit coordinates to clean host ref from Blast results Draft of Ref Curator class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import SeqIO\n",
      "\n",
      "# FUNCTION FROM ISIS CLASS REFERENCEGENOME\n",
      "def import_fasta(filename):\n",
      "    \"\"\"Import fasta files in a dictionary of biopython SeqRecord\n",
      "    \"\"\"\n",
      "    # Try to open the file fist gz compressed and uncompressed\n",
      "    try: \n",
      "        if filename.rpartition(\".\")[-1] == \"gz\":\n",
      "            print(\"\\tUncompressing and extracting data\")\n",
      "            handle = gzip.open(filename, \"r\")\n",
      "        else:\n",
      "            print(\"\\tExtracting data\")\n",
      "            handle = open(filename, \"r\")\n",
      "\n",
      "        d = SeqIO.to_dict(SeqIO.parse(handle, \"fasta\"))\n",
      "        handle.close()\n",
      "        \n",
      "        return d\n",
      "        \n",
      "    # Try to open the file fist gz compressed and uncompressed\n",
      "    except IOError:\n",
      "           print('CRITICAL ERROR. The fasta file ' + filename + ' is not readable. Exit')\n",
      "           exit\n",
      "\n",
      "def curate_ref (query, subject, evalue):\n",
      "    \n",
      "    print (\"Searching for virus homologies in host genome\")\n",
      "    hits = blastn_hits(query, subject, evalue)\n",
      "    print (hits)\n",
      "    \n",
      "    if not hits:\n",
      "        print (\"No hits found. The original host genome sequence will not be edited\")\n",
      "    else :\n",
      "        print (\"\\nImporting host genome for hard masking of homologies\")\n",
      "        genome = import_fasta(subject)\n",
      "        \n",
      "        # For all reference in which a blast hit was found \n",
      "        for ref, coord_list in hits.items():\n",
      "            # Transform the reference sequence to modify in a mutable sequence\n",
      "            print (\"Editing reference sequence : {}\".format(ref))\n",
      "            genome[ref].seq = genome[ref].seq.tomutable()\n",
      "            # For all blast hit coord found in the current reference\n",
      "            for start, end in coord_list:\n",
      "                # For all position between start en end coordinates modify the base by N\n",
      "                for position in range (start, end):\n",
      "                    genome[ref].seq[position] = 'N'\n",
      "        \n",
      "        # Write the new reference in fasta format\n",
      "        genome_basename = subject.rpartition('/')[2].partition('.')[0]\n",
      "        print (\"Writing new version of {} in which homology with the virus are masked\".format(genome_basename))\n",
      "        with open(genome_basename + \"_masked.fa\", 'w') as f:\n",
      "            for ref in genome.values():\n",
      "                f.write(ref.format(\"fasta\"))\n",
      "    print (\"DONE\") \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "start_time = time.time()\n",
      "\n",
      "curate_ref(\"../data/frag.fa\", \"../data/multi.fa\", 10)\n",
      "\n",
      "print \"\\nExecution time {} seconds\".format(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Searching for virus homologies in host genome\n",
        "Creating subject database\n",
        "\n",
        "\n",
        "Building a new DB, current time: 05/22/2014 19:03:16\n",
        "New DB name:   ../data/multi.fa\n",
        "New DB title:  ../data/multi.fa\n",
        "Sequence type: Nucleotide\n",
        "Keep Linkouts: T\n",
        "Keep MBits: T\n",
        "Maximum file size: 1000000000B\n",
        "Adding sequences from FASTA; added 5 sequences in 0.000766039 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Blast query against subject database\n",
        "8 hit(s) found"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'Ad5': [[3517, 3640], [2183, 2194]], 'Helper': [[993, 1037], [6010, 6022], [6450, 6461], [5670, 5680], [12485, 12495]], 'Phage_lambda_genome_J02459.1': [[1166, 1177]]}\n",
        "Importing host genome for hard masking of homologies\n",
        "\tExtracting data\n",
        "Editing reference sequence : Ad5\n",
        "Editing reference sequence : Helper\n",
        "Editing reference sequence : Phage_lambda_genome_J02459.1\n",
        "Writing new version of multi in which homology with the virus are masked\n",
        "DONE\n",
        "\n",
        "Execution time 0.215221166611 seconds\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It works pretty fast with a short sequence and subject. Now let's try it with the whole mouse genome vs an rAAV vector"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "start_time = time.time()\n",
      "\n",
      "curate_ref(\"../data/AAV_RSV_GFP.fa\", \"../data/mm10.fa\", 10)\n",
      "\n",
      "print \"\\nExecution time {} seconds\".format(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Searching for virus homologies in host genome\n",
        "Creating subject database\n",
        "\n",
        "\n",
        "Building a new DB, current time: 05/22/2014 19:05:55\n",
        "New DB name:   ../data/mm10.fa\n",
        "New DB title:  ../data/mm10.fa\n",
        "Sequence type: Nucleotide\n",
        "Keep Linkouts: T\n",
        "Keep MBits: T\n",
        "Maximum file size: 1000000000B\n",
        "Adding sequences from FASTA; added 66 sequences in 37.2409 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Blast query against subject database\n",
        "82 hit(s) found"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "{'chr7': [[94737490, 94737516], [19426491, 19426538], [29229444, 29229476], [29229444, 29229476]], 'chr5': [[106926004, 106926034], [106926004, 106926034]], 'chr4': [[145768347, 145768379], [146257233, 146257265], [146597820, 146597852]], 'chr3': [[53139723, 53139747], [108069438, 108069459], [108806632, 108806657]], 'chr2': [[76167874, 76167906]], 'chr1': [[135431782, 135431802]], 'chr14': [[9712542, 9712567]], 'chr9': [[25988281, 25988307], [10114568, 10114593], [21196729, 21196752], [21196729, 21196752], [21196729, 21196752], [21196729, 21196752], [45047714, 45047742], [59962726, 59962756]], 'chrX': [[120341475, 120341508]], 'chr13': [[105389688, 105389721]], 'chr12': [[115158705, 115158736], [115208397, 115208428], [115372287, 115372318], [115461301, 115461332], [115758286, 115758317], [115802950, 115802981], [115120050, 115120081], [115335384, 115335415], [115507847, 115507878], [114583871, 114583902], [114991410, 114991441], [115888398, 115888429], [114708950, 114708983], [114736547, 114736580], [114740710, 114740743], [114746575, 114746608], [114788674, 114788707], [116000330, 116000363], [115848183, 115848217], [114666174, 114666207], [114773230, 114773263], [114851492, 114851525], [114880190, 114880223], [115055527, 115055558], [115495927, 115495958], [115623463, 115623494], [115790896, 115790927], [115920581, 115920612], [114469404, 114469435], [114598195, 114598229], [114677050, 114677081], [114963683, 114963714], [115145789, 115145820], [115193977, 115194008], [115359442, 115359473], [115593412, 115593443], [50962553, 50962576], [73507255, 73507283], [73507255, 73507283], [114555911, 114555941], [115131678, 115131708], [115344840, 115344870], [115692191, 115692219]], 'chr11': [[105405046, 105405075]], 'chr10': [[21803986, 21804030], [96251960, 96251991]], 'chr17': [[76074925, 76074954], [59435556, 59435583], [85732858, 85732878]], 'chr15': [[74947775, 74947819], [8584656, 8584686], [54513789, 54513829]], 'chr8': [[82071122, 82071150], [118282667, 118282697]], 'chr18': [[33170801, 33170827], [38919602, 38919635], [38919602, 38919635]]}\n",
        "Importing host genome for hard masking of homologies\n",
        "\tExtracting data\n",
        "Editing reference sequence : chr7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chrX"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr15\n",
        "Editing reference sequence : chr8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Editing reference sequence : chr18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Writing new version of mm10 in which homology with the virus are masked\n",
        "DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Execution time 169.851909876 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That is pretty impressive taking into account that the mouse genome blast index was build, the mouse genome was imported, modified and rewritten..."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}